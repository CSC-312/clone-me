import io
import os
import sys
from datetime import datetime
import pandas as pd
from google import genai
from google.genai import types
from loguru import logger
from dotenv import load_dotenv

now = datetime.now()
load_dotenv()

logger.remove()
logger.add(sink=sys.stdout, format="<level>{level}</level>: {message}", colorize=True, level="INFO")

sheet_names = pd.ExcelFile("data/all-data.xlsx", engine="openpyxl").sheet_names[0:4]

df_uwc = pd.read_excel(
    "data/all-data.xlsx", sheet_name=sheet_names[0], engine="openpyxl"
)
df_sub = pd.read_excel(
    "data/all-data.xlsx", sheet_name=sheet_names[1], engine="openpyxl"
)
df_yt = pd.read_excel(
    "data/all-data.xlsx", sheet_name=sheet_names[2], engine="openpyxl"
)
df_pdf = pd.read_excel(
    "data/all-data.xlsx", sheet_name=sheet_names[3], engine="openpyxl"
)

dfs = [df_uwc, df_sub, df_yt, df_pdf]

for df in dfs:
    df.dropna(inplace=True)

df = pd.concat(dfs, ignore_index=True)

logger.debug(f"Total number of documents to process: {len(df)}")


def generate(text: str):
    client = genai.Client(
        api_key=os.environ.get("GEMINI_API_KEY"),
    )

    model = "gemini-2.5-flash-lite"
    contents = [
        types.Content(
            role="user",
            parts=[
                types.Part.from_text(
                    text=f"""generate structured q/a and relevent q/a pairs that can be used to fine tune a Large Language model, keys must be (question & answer). Q/a must be informational and not redundant, it must explain something about UWC(University of the Western Cape) or can be in the context of the document.
                        ignore any information that is not relevant/informative enough and is a once off event before the year 2025. If it is before 2025 it must be strictly be relevant information. For transcripts(you may know if its a transcript if you see "[Music]","[Applause]" etc. ) if words/names are not clear(indicated by lower case means autogenerated transcript), ignore them.

                         {text}

                    """
                ),
            ],
        ),
    ]
    generate_content_config = types.GenerateContentConfig(
        temperature=0.4,
        thinking_config=types.ThinkingConfig(
            thinking_budget=4032,
        ),
        response_mime_type="application/json",
    )

    response = ""
    for chunk in client.models.generate_content_stream(
        model=model,
        contents=contents,
        config=generate_content_config,
    ):
        if chunk.text:
            response += chunk.text
    return response


if __name__ == "__main__":
    path_to_save_to = "data/fine_tune"
    if os.path.exists(path_to_save_to):
        pass
    else:
        os.mkdir(path_to_save_to)

    for pdf in df.iterrows():
        idx = pdf[0]
        url = pdf[1]["url"]
        url = (
            url.replace("https://", "")
            .replace("/", "_")
            .replace(".", "_")
            .replace("?", "_".replace("=", "_"))
        )

        text = pdf[1]["text"]
        filepath = os.path.join(path_to_save_to, f"{url}.csv")

        if os.path.exists(filepath):
            logger.debug(f"File already exists for {url}, skipping...")
            continue


        logger.info(
            f"[{idx}/{len(df)}] Genertaing Questions and Answers Pairs for {url}.."
        )
        qa_pair = generate(text=text)
        pd.read_json(io.StringIO(qa_pair)).to_csv(
            f"{path_to_save_to}/{url}.csv", index=False
        )
